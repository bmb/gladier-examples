{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dials V3 funcX Flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import shortuuid\n",
    "\n",
    "from funcx.sdk.client import FuncXClient\n",
    "from fair_research_login import NativeClient\n",
    "from globus_automate_client import (create_flows_client, graphviz_format, \n",
    "                                    state_colors_for_log, create_action_client, \n",
    "                                    create_flows_client)\n",
    "from globus_automate_client.token_management import CLIENT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticate\n",
    "\n",
    "Auth with the funcX and Automate clients.\n",
    "\n",
    "Note: You will still need to grant access to the flow later on in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fxc = FuncXClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_client = create_flows_client(CLIENT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an auth token to HTTPS download from petrel#globuslabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = NativeClient(client_id='7414f0b4-7d05-4bb6-bb00-076fa3f17cf5')\n",
    "tokens = client.login(requested_scopes=['https://auth.globus.org/scopes/56ceac29-e98a-440a-a594-b41e7a084b62/all'])\n",
    "auth_token = tokens[\"petrel_https_server\"]['access_token']\n",
    "headers = {'Authorization': f'Bearer {auth_token}'}\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Setup\n",
    "## Edit things here only!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##location of the containers inside the resource\n",
    "test_container_path = \"/home/rvescovi/.funcx/containers/test.simg\"\n",
    "dials_container_path = \"/home/rvescovi/.funcx/containers/dials_v3.simg\"\n",
    "\n",
    "#funcx endpoint configuration for theta\n",
    "theta_conf = {'endpoint': '8f2f2eab-90d2-45ba-a771-b96e6d530cad',\n",
    "              'local_endpoint': '8f2f2eab-90d2-45ba-a771-b96e6d530cad',\n",
    "              'data_dir': '/projects/APSDataAnalysis/Braid/data/SSX',\n",
    "              'proc_dir': f'/projects/APSDataAnalysis/Braid/process/'}\n",
    "\n",
    "#funcx endpoint configuration for midway \n",
    "midway_conf = {'endpoint': 'd86e31f7-71b2-4e42-8a54-7bc9d5e79df9',\n",
    "              'local_endpoint': 'de6a8104-e53e-4dbd-82f1-2e9a09462a31',\n",
    "              'data_dir': '/projects/APSDataAnalysis/Braid/data/SSX',\n",
    "              'proc_dir': f'/project2/chard/ryan/Braid/process/'}\n",
    "\n",
    "##Choose which resource to run.\n",
    "conf = theta_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funcX setup\n",
    "Register the containers and functions for the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An initial container to use\n",
    "init_cont_id = fxc.register_container(location=test_container_path, container_type='singularity')\n",
    "# And the container we will download during the flow\n",
    "dials_cont_id = fxc.register_container(location=dials_container_path, container_type='singularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_cont(data):\n",
    "    \"\"\"Download the container and dataset\"\"\"\n",
    "    import os\n",
    "    import requests\n",
    "\n",
    "\n",
    "    server_url = data.get('server_url', \"\")\n",
    "    container_name = data.get('container_name', \"\")\n",
    "    container_url = os.path.join(server_url,container_name)\n",
    "\n",
    "    if not server_url | container_name:\n",
    "        return \"No container found on server\"\n",
    "\n",
    "    headers = data['headers']\n",
    "\n",
    "\n",
    "    if not os.path.isfile(data['container_path']):\n",
    "        r = requests.get(container_url, headers=headers)\n",
    "        open(data['container_path'] , 'wb').write(r.content)\n",
    "    \n",
    "    return 'done'\n",
    "\n",
    "download_cont_fxid = fxc.register_function(download_cont, container_uuid=init_cont_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(data):\n",
    "    import os\n",
    "    import requests\n",
    "\n",
    "    data_dir = data['data_dir']\n",
    "    headers = data['headers']\n",
    "    dataset_url = data['dataset_url']\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    dataset_name = dataset_url.split(\"/\")[-1]\n",
    "    \n",
    "    dataset_path = os.path.join(data_dir, dataset_name)\n",
    "    \n",
    "    if not os.path.isfile(dataset_path):\n",
    "        r = requests.get(dataset_url, headers=headers)\n",
    "        open(dataset_path , 'wb').write(r.content)\n",
    "    \n",
    "    return 'done'\n",
    "\n",
    "download_data_fxid = fxc.register_function(download_data, container_uuid=init_cont_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap_data(data):\n",
    "    import os\n",
    "    import tarfile\n",
    "\n",
    "    data_dir = data['data_dir']\n",
    "    dataset_url = data['dataset_url']\n",
    "    \n",
    "    dataset_name = dataset_url.split(\"/\")[-1]\n",
    "    dataset_path = os.path.join(data_dir, dataset_name)\n",
    "    \n",
    "    folder_name = dataset_name.split(\".\")[0] ##change for os.path.filename??\n",
    "    folder_path = os.path.join(data_dir,folder_name)\n",
    "    os.mkdir(folder_path)\n",
    "    \n",
    "    if os.path.isfile(dataset_path):\n",
    "        with tarfile.open(dataset_path) as file:\n",
    "            file.extractall(folder_path)\n",
    "        return folder_path\n",
    "    return 'file does not exist!'\n",
    "  \n",
    "unwrap_data_fxid = fxc.register_function(unwrap_data, container_uuid=init_cont_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcx_create_phil(data):\n",
    "    \"\"\"Create a phil file\"\"\"\n",
    "    import json\n",
    "    import os\n",
    "    from string import Template\n",
    "\n",
    "    proc_dir = data['proc_dir']\n",
    "    data_dir = os.path.split(data['input_files'])[0]\n",
    "    run_num = data['input_files'].split(\"_\")[-2]\n",
    "    \n",
    "    \n",
    "    if 'suffix' in data:\n",
    "        phil_name = f\"{proc_dir}/process_{run_num}_{data['suffix']}.phil\"\n",
    "    else:\n",
    "        phil_name = f\"{proc_dir}/process_{run_num}.phil\"\n",
    "\n",
    "    \n",
    "    unit_cell = data.get('unit_cell', None)\n",
    "    \n",
    "    ##opening existing files\n",
    "    beamline_json = os.path.join(data_dir,f\"beamline_run{run_num}.json\")\n",
    "    mask = os.path.join(data_dir,data.get('mask', 'mask.pickle'))\n",
    "\n",
    "    beamline_data = None\n",
    "\n",
    "    try:\n",
    "        with open(beamline_json, 'r') as fp:\n",
    "            beamline_data = json.loads(fp.read())\n",
    "\n",
    "        if not unit_cell:\n",
    "            unit_cell = beamline_data['user_input']['unit_cell']\n",
    "\n",
    "        unit_cell = unit_cell.replace(\",\", \" \")\n",
    "        space_group = beamline_data['user_input']['space_group']\n",
    "        det_distance = float(beamline_data['beamline_input']['det_distance']) * -1.0\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    template_data = {'det_distance': det_distance,\n",
    "                     'unit_cell': unit_cell,\n",
    "                     'nproc': data['nproc'],\n",
    "                     'space_group': space_group,\n",
    "                     'beamx': data['beamx'],\n",
    "                     'beamy': data['beamy'],\n",
    "                     'mask': mask}\n",
    "\n",
    "    template_phil = Template(\"\"\"spotfinder.lookup.mask=$mask\n",
    "integration.lookup.mask=$mask\n",
    "spotfinder.filter.min_spot_size=2\n",
    "significance_filter.enable=True\n",
    "#significance_filter.isigi_cutoff=1.0\n",
    "mp.nproc = $nproc\n",
    "mp.method=multiprocessing\n",
    "refinement.parameterisation.detector.fix=none\n",
    "geometry {\n",
    "  detector {\n",
    "      panel {\n",
    "                fast_axis = 0.9999673162585729, -0.0034449798523932267, -0.007314268824966957\n",
    "                slow_axis = -0.0034447744696749034, -0.99999406591948, 4.0677756813531234e-05\n",
    "                origin    = $beamx, $beamy, $det_distance\n",
    "                }\n",
    "            }\n",
    "         }\n",
    "indexing {\n",
    "  known_symmetry {\n",
    "    space_group = $space_group\n",
    "    unit_cell = $unit_cell\n",
    "  }\n",
    "  stills.indexer=stills\n",
    "  stills.method_list=fft1d\n",
    "  multiple_lattice_search.max_lattices=3\n",
    "}\"\"\")\n",
    "    phil_data = template_phil.substitute(template_data)\n",
    "\n",
    "    if not os.path.exists(proc_dir):\n",
    "        os.mkdir(proc_dir)\n",
    "        \n",
    "    with open(phil_name, 'w') as fp:\n",
    "        fp.write(phil_data)\n",
    "    return phil_name\n",
    "\n",
    "create_phil_fxid = fxc.register_function(funcx_create_phil, container_uuid=init_cont_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcx_stills_process(data):\n",
    "    import os\n",
    "    import subprocess\n",
    "    from distutils.dir_util import copy_tree\n",
    "    from subprocess import PIPE\n",
    "\n",
    "    \n",
    "    proc_dir = data['proc_dir']\n",
    "    input_files = data['input_files']\n",
    "\n",
    "    run_num = data['input_files'].split(\"_\")[-2]\n",
    "    \n",
    "    \n",
    "    if 'suffix' in data:\n",
    "        phil_name = f\"{proc_dir}/process_{run_num}_{data['suffix']}.phil\"\n",
    "    else:\n",
    "        phil_name = f\"{proc_dir}/process_{run_num}.phil\"\n",
    "\n",
    "    file_end = data['input_range'].split(\"..\")[-1]\n",
    "  \n",
    "    if not \"timeout\" in data:\n",
    "        data[\"timeout\"] = 0\n",
    "        \n",
    "    cmd = f'source /usr/local/dials-dev20210305/dials_env.sh && dials.stills_process {phil_name} {input_files} > log-{file_end}.txt'\n",
    "\n",
    "    \n",
    "    os.chdir(proc_dir) ##Need to guarantee the worker is at the correct location..\n",
    "    res = subprocess.run(cmd, stdout=PIPE, stderr=PIPE,\n",
    "                             shell=True, executable='/bin/bash')\n",
    "    \n",
    "    return str(res.stdout)\n",
    "\n",
    "\n",
    "stills_fxid = fxc.register_function(funcx_stills_process, container_uuid=dials_cont_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcx_plot_ssx(data):\n",
    "    import os\n",
    "    import json\n",
    "    import shutil\n",
    "    import glob\n",
    "    import subprocess\n",
    "    import numpy as np\n",
    "    from subprocess import PIPE\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "    data_dir = data['data_dir']\n",
    "    proc_dir = data['proc_dir']\n",
    "    data_dir = os.path.split(data['input_files'])[0]\n",
    "    run_num = data['input_files'].split(\"_\")[-2]\n",
    "    \n",
    "    \n",
    "    if 'suffix' in data:\n",
    "        phil_name = f\"{proc_dir}/process_{run_num}_{data['suffix']}.phil\"\n",
    "    else:\n",
    "        phil_name = f\"{proc_dir}/process_{run_num}.phil\"\n",
    "\n",
    "\n",
    "    ##opening existing files\n",
    "    beamline_json = os.path.join(data_dir,f\"beamline_run{run_num}.json\")\n",
    "\n",
    "    beamline_data = None\n",
    "    with open(beamline_json, 'r') as fp:\n",
    "        beamline_data = json.loads(fp.read())\n",
    "\n",
    "    xdim = int(beamline_data['user_input']['x_num_steps'])\n",
    "    ydim = int(beamline_data['user_input']['y_num_steps'])\n",
    "\n",
    "    # Get the list of int files in this range\n",
    "    int_files = glob.glob(os.path.join(proc_dir,'int-*.pickle'))\n",
    "\n",
    "    ##########\n",
    "    #lattice_counts = get_lattice_counts(xdim, ydim, int_files)\n",
    "    ##########\n",
    "    lattice_counts = np.zeros(xdim*ydim)\n",
    "    for int_file in int_files:\n",
    "        int_file = int_file.rstrip('.pickle\\n')\n",
    "        index = int(int_file.split('_')[-1])\n",
    "        lattice_counts[index] += 1\n",
    "\n",
    "    lattice_counts = lattice_counts.reshape((ydim, xdim))\n",
    "    # reverse the order of alternating rows\n",
    "    lattice_counts[1::2, :] = lattice_counts[1::2, ::-1]\n",
    "    \n",
    "  \n",
    "    plot_name = f'1int-sinc-{data[\"input_range\"]}.png'\n",
    "\n",
    "    ########\n",
    "    #plot_lattice_counts(xdim, ydim, lattice_counts, plot_name)\n",
    "    ########\n",
    "\n",
    "    fig = plt.figure(figsize=(xdim/10., ydim/10.))\n",
    "    plt.axes([0, 0, 1, 1])  # Make the plot occupy the whole canvas\n",
    "    plt.axis('off')\n",
    "    plt.imshow(lattice_counts, cmap='hot', interpolation=None, vmax=4)\n",
    "    plt.savefig(plot_name)\n",
    "\n",
    "\n",
    "    exp_name = data['input_files'].split(\"/\")[-1].split(\"_\")[0]\n",
    "\n",
    "    # create an images directory\n",
    "    image_dir = f\"{proc_dir}/{exp_name}_images\"\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "\n",
    "    int_file = f\"{image_dir}/{exp_name}_ints.txt\"\n",
    "    with open(int_file, 'w+') as fp:\n",
    "        fp.write(\"\\n\".join(i for i in int_files))\n",
    "\n",
    "    os.chdir(image_dir)\n",
    "\n",
    "    cmd = f\"source source /usr/local/dials-dev20210305/dials_env.sh && \\\n",
    "        dials.unit_cell_histogram ../{proc_dir}_processing/*integrated_experiments.json\"\n",
    "\n",
    "    subprocess.run(cmd, stdout=PIPE, stderr=PIPE, shell=True, executable='/bin/bash')\n",
    "\n",
    "    return plot_name\n",
    "\n",
    "plot_ssx_fxid = fxc.register_function(funcx_plot_ssx, container_uuid=dials_cont_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flow_definition = {\n",
    "  \"Comment\": \"Dials V3 Flow\",\n",
    "  \"StartAt\": \"DownloadContainer\",\n",
    "  \"States\": {\n",
    "    \"DownloadContainer\": {\n",
    "      \"Comment\": \"Download the container\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://api.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/all\",\n",
    "      \"Parameters\": {\n",
    "          \"tasks\": [{\n",
    "            \"endpoint.$\": \"$.input.funcx_local_ep\",\n",
    "            \"func.$\": \"$.input.download_cont_fxid\",\n",
    "            \"payload.$\": \"$.input\"\n",
    "        }]\n",
    "      },\n",
    "      \"ResultPath\": \"$.Exec1Result\",\n",
    "      \"WaitTime\": 600,\n",
    "      \"Next\": \"DownloadData\"\n",
    "    },\n",
    "    \"DownloadData\": {\n",
    "      \"Comment\": \"Download the data\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://api.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/all\",\n",
    "      \"Parameters\": {\n",
    "          \"tasks\": [{\n",
    "            \"endpoint.$\": \"$.input.funcx_local_ep\",\n",
    "            \"func.$\": \"$.input.download_data_fxid\",\n",
    "            \"payload.$\": \"$.input\"\n",
    "        }]\n",
    "      },\n",
    "      \"ResultPath\": \"$.Exec2Result\",\n",
    "      \"WaitTime\": 600,\n",
    "      \"Next\": \"UnwrapData\"\n",
    "    },\n",
    "    \"UnwrapData\": {\n",
    "      \"Comment\": \"Unwrap Data\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://api.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/all\",\n",
    "      \"Parameters\": {\n",
    "          \"tasks\": [{\n",
    "            \"endpoint.$\": \"$.input.funcx_local_ep\",\n",
    "            \"func.$\": \"$.input.unwrap_data_fxid\",\n",
    "            \"payload.$\": \"$.input\"\n",
    "        }]\n",
    "      },\n",
    "      \"ResultPath\": \"$.Exec3Result\",\n",
    "      \"WaitTime\": 600,\n",
    "      \"Next\": \"DialsCreatePhil\"\n",
    "    },\n",
    "    \"DialsCreatePhil\": {\n",
    "      \"Comment\": \"Create Dials Phil\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://api.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/all\",\n",
    "      \"Parameters\": {\n",
    "          \"tasks\": [{\n",
    "            \"endpoint.$\": \"$.input.funcx_ep\",\n",
    "            \"func.$\": \"$.input.create_phil_fxid\",\n",
    "            \"payload.$\": \"$.input\"\n",
    "        }]\n",
    "      },\n",
    "      \"ResultPath\": \"$.Exec4Result\",\n",
    "      \"WaitTime\": 600,\n",
    "      \"Next\": \"DialsStills\"\n",
    "    },\n",
    "    \"DialsStills\": {\n",
    "      \"Comment\": \"Dials Stills Function\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://api.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/all\",\n",
    "      \"Parameters\": {\n",
    "          \"tasks\": [{\n",
    "            \"endpoint.$\": \"$.input.funcx_ep\",\n",
    "            \"func.$\": \"$.input.stills_fxid\",\n",
    "            \"payload.$\": \"$.input\"\n",
    "        }]\n",
    "      },\n",
    "      \"ResultPath\": \"$.Exec5Result\",\n",
    "      \"WaitTime\": 600,\n",
    "      \"Next\": \"PlotSSX\"\n",
    "    },\n",
    "    \"PlotSSX\": {\n",
    "      \"Comment\": \"Dials Plot Function\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://api.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/all\",\n",
    "      \"Parameters\": {\n",
    "          \"tasks\": [{\n",
    "            \"endpoint.$\": \"$.input.funcx_ep\",\n",
    "            \"func.$\": \"$.input.plot_fxid\",\n",
    "            \"payload.$\": \"$.input\"\n",
    "        }]\n",
    "      },\n",
    "      \"ResultPath\": \"$.Exec6Result\",\n",
    "      \"WaitTime\": 600,\n",
    "      \"End\": True\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flow = flows_client.deploy_flow(flow_definition, title=\"Dials V3 Example Flow\")\n",
    "flow_id = flow['id']\n",
    "flow_scope = flow['globus_auth_scope']\n",
    "print(f'Newly created flow with id:\\n{flow_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define input for the flow\n",
    "\n",
    "The input to the flow needs to specify what data to process, where it is located, and where to put it for analysis. The flow also requires the funcX function endpoint ids to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the name for the processing folder intermediate results\n",
    "experiment_name = 'braid_dials_v3'\n",
    "run_name = experiment_name + '_' + shortuuid.uuid()\n",
    "\n",
    "print(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the range of files to process\n",
    "proc_range = \"{00001..00050}\"\n",
    "\n",
    "flow_input = {\n",
    "    \"input\": {\n",
    "        #HTTPS-Download Container variables\n",
    "        \"server_url\":\"https://45a53408-c797-11e6-9c33-22000a1e3b52.e.globus.org/Braid/containers\",\n",
    "        \"container_name\": \"dials_v3_example.simg\",\n",
    "        \"container_path\": dials_container_path, ##defined in the funcx container configuration\n",
    "        \"headers\": headers,\n",
    "        \n",
    "        #SingleFile-Download Variables\n",
    "        \"dataset_url\": \"https://45a53408-c797-11e6-9c33-22000a1e3b52.e.globus.org/Braid/data/ssx_example/levin_29.tar.xz\",\n",
    "        \"data_dir\": conf['data_dir'],\n",
    "\n",
    "        #Processing variables\n",
    "        \"proc_dir\": os.path.join(conf['proc_dir'],run_name),\n",
    "\n",
    "        #Dials specific variables.\n",
    "        \"input_files\": f\"{conf['data_dir']}/levin_29/Levin_29_{proc_range}.cbf\", \n",
    "        \"input_range\": proc_range[1:-1],\n",
    "        \"nproc\": 10,\n",
    "        \"beamx\": \"-214.400\",\n",
    "        \"beamy\": \"218.200\",\n",
    "\n",
    "        #Dials funcX functions\n",
    "        \"create_phil_fxid\": create_phil_fxid,\n",
    "        \"stills_fxid\": stills_fxid,\n",
    "        \"plot_fxid\": plot_ssx_fxid,\n",
    "\n",
    "        #Utility funcX functions\n",
    "        \"download_cont_fxid\": download_cont_fxid,\n",
    "        \"download_data_fxid\": download_data_fxid,\n",
    "        \"unwrap_data_fxid\": unwrap_data_fxid,\n",
    "\n",
    "        \n",
    "        # funcX endpoints\n",
    "        \"funcx_ep\": conf['endpoint'],\n",
    "        \"funcx_local_ep\": conf['local_endpoint'],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the flow\n",
    "\n",
    "This will require you to authenticate and grant access to the flow to use Transfer and funcX on your behalf.\n",
    "\n",
    "The flow should take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_action = flows_client.run_flow(flow_id, flow_scope, flow_input)\n",
    "print(flow_action)\n",
    "flow_action_id = flow_action['action_id']\n",
    "flow_status = flow_action['status']\n",
    "print(f'Flow action started with id: {flow_action_id}')\n",
    "while flow_status == 'ACTIVE':\n",
    "    time.sleep(10)\n",
    "    flow_action = flows_client.flow_action_status(flow_id, flow_scope, flow_action_id)\n",
    "    flow_status = flow_action['status']\n",
    "    print(f'Flow status: {flow_status}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}