{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigen funcX Flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import shortuuid\n",
    "\n",
    "from funcx.sdk.client import FuncXClient\n",
    "from fair_research_login import NativeClient\n",
    "from globus_automate_client import create_flows_client\n",
    "from globus_automate_client.token_management import CLIENT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticate\n",
    "\n",
    "Auth with the funcX and Automate clients.\n",
    "\n",
    "Note: You will still need to grant access to the flow later on in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fxc = FuncXClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_client = create_flows_client(CLIENT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = NativeClient(client_id='7414f0b4-7d05-4bb6-bb00-076fa3f17cf5')\n",
    "tokens = client.login(requested_scopes=['https://auth.globus.org/scopes/56ceac29-e98a-440a-a594-b41e7a084b62/all'])\n",
    "auth_token = tokens[\"petrel_https_server\"]['access_token']\n",
    "headers = {'Authorization': f'Bearer {auth_token}'}\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Setup\n",
    "## Edit things here only!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Container name\n",
    "### should be the same within the container repo and resource\n",
    "container_name = \"eigen.simg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcx endpoint configuration for theta\n",
    "theta_conf = {'endpoint': '8f2f2eab-90d2-45ba-a771-b96e6d530cad',\n",
    "              'local_endpoint': '8f2f2eab-90d2-45ba-a771-b96e6d530cad',\n",
    "              'data_dir': '/projects/APSDataAnalysis/Braid/data/XPCS/',\n",
    "              'proc_dir': '/projects/APSDataAnalysis/Braid/process/',\n",
    "              'cont_dir': '/home/rvescovi/.funcx/containers/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcx endpoint configuration for midway \n",
    "midway_conf = {'endpoint': '159eeda6-d2c3-4e87-b9b6-98711a938b48',\n",
    "              'local_endpoint': 'dede52af-cee9-4e44-b017-ceb0c8f584cb',\n",
    "              'data_dir': '/home/ravescovi/workspace/Braid/data/XPCS/',\n",
    "              'proc_dir': '/home/ravescovi/workspace/Braid/process/',\n",
    "              'cont_dir': '/home/ravescovi/.funcx/containers/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which resource to run.\n",
    "conf = theta_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register your container\n",
    "### Even though we download the container during the flow.\n",
    "#### We need to create a funcx id for it.\n",
    "eigen_cont_id = fxc.register_container(location=os.path.join(conf['cont_dir'],container_name), container_type='singularity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funcX setup\n",
    "Register the containers and functions for the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_cont(data):\n",
    "    \"\"\"Download the container and dataset\"\"\"\n",
    "    import os\n",
    "    import requests\n",
    "\n",
    "\n",
    "    server_url = data.get('container_server_url', \"\")\n",
    "    container_name = data.get('container_name', \"\")\n",
    "    headers = data['headers']\n",
    "\n",
    "    if server_url==None:\n",
    "        raise(NameError('No container `server URL` specified'))\n",
    "    if container_name==None:\n",
    "        raise(NameError('No container `name` specified'))\n",
    "\n",
    "    container_url = os.path.join(server_url,container_name)\n",
    "    \n",
    "    ##deal with container path in the system (need to be consistent with container_uid)\n",
    "    container_path = data.get('container_path', '')\n",
    "    if not container_path:\n",
    "        os.path.join(os.path.expanduser(\"~\"),'.funcx/containers')\n",
    "\n",
    "    if not os.path.exists(data['container_path']):\n",
    "        os.mkdir(data['container_path'])\n",
    "\n",
    "    #deal with overwrite?\n",
    "    if not os.path.isfile(data['container_path']):\n",
    "        container_full_name = os.path.join(data['container_path'],data['container_name'])\n",
    "        \n",
    "        r = requests.get(container_url, headers=headers)\n",
    "        if not r.status_code==200:  \n",
    "            raise r.raise_for_status()\n",
    "        open(container_full_name , 'wb').write(r.content)\n",
    "\n",
    "    return container_full_name\n",
    "\n",
    "download_cont_fxid = fxc.register_function(download_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(data):\n",
    "    import os\n",
    "    import requests\n",
    "\n",
    "    data_dir = data['data_dir']\n",
    "    headers = data['headers']\n",
    "    dataset_server = data['dataset_server_url']\n",
    "    dataset_name = data['dataset_name']\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    dataset_path = os.path.join(data_dir, dataset_name)\n",
    "    dataset_url = os.path.join(dataset_server,dataset_name)\n",
    "\n",
    "    if not os.path.isfile(dataset_path):\n",
    "        r = requests.get(dataset_url, headers=headers)\n",
    "        if not r.status_code==200:  \n",
    "            raise r.raise_for_status()\n",
    "        open(dataset_path , 'wb').write(r.content)\n",
    "    \n",
    "    return dataset_path\n",
    "\n",
    "download_data_fxid = fxc.register_function(download_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap_data(data):\n",
    "    import os\n",
    "    import tarfile\n",
    "\n",
    "\n",
    "    data_dir = data['data_dir']\n",
    "    dataset_name = data['dataset_name']\n",
    "\n",
    "    dataset_path = os.path.join(data_dir, dataset_name)\n",
    "    \n",
    "    folder_name = dataset_name.split(\".\")[0] ##change for os.path.filename??\n",
    "    folder_path = os.path.join(data_dir,folder_name)\n",
    "    os.mkdir(folder_path)\n",
    "    \n",
    "    if os.path.isfile(dataset_path):\n",
    "        with tarfile.open(dataset_path) as file:\n",
    "            file.extractall(folder_path)\n",
    "        return folder_path\n",
    "    else:\n",
    "        raise 'file does not exist!'\n",
    "  \n",
    "unwrap_data_fxid = fxc.register_function(unwrap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xpcs_corr(event):\n",
    "    import os\n",
    "    import subprocess\n",
    "    from subprocess import PIPE\n",
    "\n",
    "    \n",
    "    proc_dir = event['proc_dir']\n",
    "    if not os.path.exists(proc_dir):\n",
    "        os.mkdir(proc_dir)\n",
    "\n",
    "    hdf_file = event['data']['hdf']\n",
    "    imm_file = event['data']['imm']\n",
    "    \n",
    "    flags = event['data'].get('flags', \"\")\n",
    "\n",
    "    cmd = f\"corr {hdf_file} -imm {imm_file} {flags}\"\n",
    "  \n",
    "    res = subprocess.run(cmd, stdout=PIPE, stderr=PIPE,\n",
    "                             shell=True, executable='/bin/bash')\n",
    "    \n",
    "    with open(os.path.join(proc_dir,'corr_output.log'), 'w+') as f:\n",
    "                f.write(res.stdout.decode('utf-8'))\n",
    "\n",
    "    with open(os.path.join(proc_dir,'corr_errors.log'), 'w+') as f:\n",
    "                f.write(res.stderr.decode('utf-8'))\n",
    "    \n",
    "    return str(res.stdout)\n",
    "\n",
    "corr_fxid = fxc.register_function(xpcs_corr, container_uuid=eigen_cont_id)"
   ]
  },
  {
   "source": [
    "# Flow Check Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import json\n",
    "from pprint import pprint\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def flow_check(flow_action, refresh=10):\n",
    "    \n",
    "    start = datetime.fromisoformat(flow_action['start_time'])\n",
    "\n",
    "    while True:\n",
    "        flow_action_id = flow_action['action_id']\n",
    "        flow_action = flows_client.flow_action_status(flow_id, flow_scope, flow_action_id)\n",
    "        flow_status = flow_action['status']\n",
    "\n",
    "        print(f'Flow status: {flow_status}')\n",
    "        \n",
    "        if flow_status == 'ACTIVE': \n",
    "            now = datetime.now(timezone.utc)\n",
    "            print(f'Time elapsed: {now - start}')\n",
    "            pprint(json.dumps(flow_action.data, indent = 2, sort_keys=True))\n",
    "\n",
    "        elif flow_status == 'FAILED':\n",
    "            complete = datetime.fromisoformat(flow_action['completion_time'])\n",
    "            print(f'Time elapsed: {complete - start}')\n",
    "            break\n",
    "        elif flow_status == 'SUCCEEDED':\n",
    "            complete = datetime.fromisoformat(flow_action['completion_time'])\n",
    "            print(f'Time elapsed: {complete - start}')\n",
    "            break\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        time.sleep(refresh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flow_definition = {\n",
    "  \"Comment\": \"Eigen Flow\",\n",
    "  \"StartAt\": \"Download Container\",\n",
    "  \"States\": {\n",
    "    \"Download Container\": {\n",
    "      \"Comment\": \"Download the container\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://api.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/all\",\n",
    "      \"Parameters\": {\n",
    "          \"tasks\": [{\n",
    "            \"endpoint.$\": \"$.input.funcx_local_ep\",\n",
    "            \"func.$\": \"$.input.download_cont_fxid\",\n",
    "            \"payload.$\": \"$.input\"\n",
    "        }]\n",
    "      },\n",
    "      \"ResultPath\": \"$.Exec1Result\",\n",
    "      \"WaitTime\": 600,\n",
    "      \"Next\": \"Download Data\"\n",
    "    },\n",
    "    \"Download Data\": {\n",
    "      \"Comment\": \"Download the data\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://api.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/all\",\n",
    "      \"Parameters\": {\n",
    "          \"tasks\": [{\n",
    "            \"endpoint.$\": \"$.input.funcx_local_ep\",\n",
    "            \"func.$\": \"$.input.download_data_fxid\",\n",
    "            \"payload.$\": \"$.input\"\n",
    "        }]\n",
    "      },\n",
    "      \"ResultPath\": \"$.Exec2Result\",\n",
    "      \"WaitTime\": 600,\n",
    "      \"Next\": \"Unwrap Data\"\n",
    "    },\n",
    "    \"Unwrap Data\": {\n",
    "      \"Comment\": \"Unwrap the data\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://api.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/all\",\n",
    "      \"Parameters\": {\n",
    "          \"tasks\": [{\n",
    "            \"endpoint.$\": \"$.input.funcx_local_ep\",\n",
    "            \"func.$\": \"$.input.download_data_fxid\",\n",
    "            \"payload.$\": \"$.input\"\n",
    "        }]\n",
    "      },\n",
    "      \"ResultPath\": \"$.Exec3Result\",\n",
    "      \"WaitTime\": 600,\n",
    "      \"Next\": \"Eigen Corr\"\n",
    "    },\n",
    "    \"Eigen Corr\": {\n",
    "      \"Comment\": \"Eigen Corr\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://api.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/all\",\n",
    "      \"Parameters\": {\n",
    "          \"tasks\": [{\n",
    "            \"endpoint.$\": \"$.input.funcx_ep\",\n",
    "            \"func.$\": \"$.input.corr_fxid\",\n",
    "            \"payload.$\": \"$.input\"\n",
    "        }]\n",
    "      },\n",
    "      \"ResultPath\": \"$.Exec4Result\",\n",
    "      \"WaitTime\": 600,\n",
    "      \"End\": True\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flow = flows_client.deploy_flow(flow_definition, title=\"Eigen Example flow\")\n",
    "flow_id = flow['id']\n",
    "flow_scope = flow['globus_auth_scope']\n",
    "print(f'Newly created flow with id:\\n{flow_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define input for the flow\n",
    "\n",
    "The input to the flow needs to specify what data to process, where it is located, and where to put it for analysis. The flow also requires the funcX function endpoint ids to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the name for the processing folder intermediate results\n",
    "experiment_name = 'braid_eigen'\n",
    "run_name = experiment_name + '_' + shortuuid.uuid()\n",
    "\n",
    "print(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the range of files to process\n",
    "\n",
    "flow_input = {\n",
    "    \"input\": {\n",
    "        #HTTPS-Download Container variables\n",
    "        \"container_server_url\":\"https://45a53408-c797-11e6-9c33-22000a1e3b52.e.globus.org/Braid/containers\",\n",
    "        \"container_name\": \"eigen_example.simg\",\n",
    "        \"container_path\": conf['cont_dir'],\n",
    "        \"headers\": headers,\n",
    "\n",
    "        #SingleFile-Download Variables\n",
    "        \"dataset_server_url\": \"https://45a53408-c797-11e6-9c33-22000a1e3b52.e.globus.org/Braid/data/xpcs_example/\",\n",
    "        \"dataset_name\": 'A001_Aerogel.tar.xz',\n",
    "        \"data_dir\": conf['data_dir'],\n",
    "\n",
    "        #Processing variables\n",
    "        \"proc_dir\": os.path.join(conf['proc_dir'],run_name),\n",
    "\n",
    "        #Eigen specific variables\n",
    "        \"data\": {\n",
    "            \"hdf\": f\"{conf['data_dir']}/A001_Aerogel_1mm_att6_Lq0_001_0001-1000/A001_Aerogel_1mm_att6_Lq0_001_0001-1000.hdf\",\n",
    "            \"imm\": f\"{conf['data_dir']}/A001_Aerogel_1mm_att6_Lq0_001_0001-1000/                 A001_Aerogel_1mm_att6_Lq0_001_00001-01000.imm\",\n",
    "        },\n",
    "\n",
    "        #Eigen funcX functions\n",
    "        \"corr_fxid\": corr_fxid,\n",
    "\n",
    "        #Utility funcX functions\n",
    "        \"download_cont_fxid\": download_cont_fxid,\n",
    "        \"download_data_fxid\": download_data_fxid,\n",
    "        \"unwrap_data_fxid\": unwrap_data_fxid,\n",
    "\n",
    "        # funcX endpoints \n",
    "        \"funcx_ep\": conf['endpoint'],\n",
    "        \"funcx_local_ep\": conf['local_endpoint'],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the flow\n",
    "\n",
    "This will require you to authenticate and grant access to the flow to use Transfer and funcX on your behalf.\n",
    "\n",
    "The flow should take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_action = flows_client.run_flow(flow_id, flow_scope, flow_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_check(flow_action, refresh=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('funcx': conda)",
   "metadata": {
    "interpreter": {
     "hash": "29c7d61c0b705a1e0ee1ff93d2482337e8314a272648cd14c87bbb9c779684f0"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}