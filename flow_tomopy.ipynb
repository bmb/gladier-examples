{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomo funcX Flow\n",
    "\n",
    "This example creates a flow to use tomopy on Theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import shortuuid\n",
    "\n",
    "from funcx.sdk.client import FuncXClient\n",
    "from fair_research_login import NativeClient\n",
    "from globus_automate_client import create_flows_client\n",
    "from globus_automate_client.token_management import CLIENT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticate\n",
    "\n",
    "Auth with the funcX and Automate clients.\n",
    "\n",
    "Note: You will still need to grant access to the flow later on in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fxc = FuncXClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_client = create_flows_client(CLIENT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = NativeClient(client_id='7414f0b4-7d05-4bb6-bb00-076fa3f17cf5') ##inverted\n",
    "tokens = client.login(requested_scopes=['https://auth.globus.org/scopes/56ceac29-e98a-440a-a594-b41e7a084b62/all'])\n",
    "auth_token = tokens[\"petrel_https_server\"]['access_token']\n",
    "headers = {'Authorization': f'Bearer {auth_token}'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Setup\n",
    "## Edit things here only!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# container name\n",
    "### should be the same within the container repo and resource\n",
    "container_name = \"tomo_example.simg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcx endpoint configuration for theta\n",
    "theta_conf = {'endpoint': '8f2f2eab-90d2-45ba-a771-b96e6d530cad',\n",
    "              'local_endpoint': '8f2f2eab-90d2-45ba-a771-b96e6d530cad',\n",
    "              'data_dir': '/projects/APSDataAnalysis/Braid/data/Tomo/',\n",
    "              'proc_dir': '/projects/APSDataAnalysis/Braid/process/',\n",
    "              'cont_dir': '/home/rvescovi/.funcx/containers/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcx endpoint configuration for midway \n",
    "midway_conf = {'endpoint': '159eeda6-d2c3-4e87-b9b6-98711a938b48',\n",
    "              'local_endpoint': 'dede52af-cee9-4e44-b017-ceb0c8f584cb',\n",
    "              'data_dir': '/home/ravescovi/workspace/Braid/data/Tomo/',\n",
    "              'proc_dir': '/home/ravescovi/workspace/Braid/process/',\n",
    "              'cont_dir': '/home/ravescovi/.funcx/containers/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which resource to run.\n",
    "conf = theta_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register your container\n",
    "### Even though we download the container during the flow.\n",
    "#### We need to create a funcx id for it.\n",
    "tomo_cont_id = fxc.register_container(location=os.path.join(conf['cont_dir'],container_name), container_type='singularity') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funcX setup\n",
    "Register the functions for the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_cont(data):\n",
    "    \"\"\"Download the container and dataset\"\"\"\n",
    "    import os\n",
    "    import requests\n",
    "\n",
    "\n",
    "    server_url = data.get('container_server_url', \"\")\n",
    "    container_name = data.get('container_name', \"\")\n",
    "    headers = data['headers']\n",
    "\n",
    "    if server_url==None:\n",
    "        raise(NameError('No container `server URL` specified'))\n",
    "    if container_name==None:\n",
    "        raise(NameError('No container `name` specified'))\n",
    "\n",
    "    container_url = os.path.join(server_url,container_name)\n",
    "    \n",
    "    ##deal with container path in the system (need to be consistent with container_uid)\n",
    "    container_path = data.get('container_path', '')\n",
    "    if not container_path:\n",
    "        os.path.join(os.path.expanduser(\"~\"),'.funcx/containers')\n",
    "\n",
    "    if not os.path.exists(data['container_path']):\n",
    "        os.mkdir(data['container_path'])\n",
    "\n",
    "    #deal with overwrite?\n",
    "    if not os.path.isfile(data['container_path']):\n",
    "        container_full_name = os.path.join(data['container_path'],data['container_name'])\n",
    "        \n",
    "        r = requests.get(container_url, headers=headers)\n",
    "        if not r.status_code==200:  \n",
    "            raise r.raise_for_status()\n",
    "        open(container_full_name , 'wb').write(r.content)\n",
    "\n",
    "    return container_full_name\n",
    "\n",
    "download_cont_fxid = fxc.register_function(download_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(data):\n",
    "    import os\n",
    "    import requests\n",
    "\n",
    "    data_dir = data['data_dir']\n",
    "    headers = data['headers']\n",
    "    dataset_server = data['dataset_server_url']\n",
    "    dataset_name = data['dataset_name']\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    dataset_path = os.path.join(data_dir, dataset_name)\n",
    "    dataset_url = os.path.join(dataset_server,dataset_name)\n",
    "\n",
    "    if not os.path.isfile(dataset_path):\n",
    "        r = requests.get(dataset_url, headers=headers)\n",
    "        if not r.status_code==200:  \n",
    "            raise r.raise_for_status()\n",
    "        open(dataset_path , 'wb').write(r.content)\n",
    "    \n",
    "    return dataset_path\n",
    "\n",
    "download_data_fxid = fxc.register_function(download_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tomo_recon(data):\n",
    "    import os\n",
    "    import subprocess\n",
    "\n",
    "\n",
    "    data_dir = data['data_dir']\n",
    "    dataset_name = data['dataset_name']\n",
    "    \n",
    "\n",
    "    dataset_path = os.path.join(data_dir, dataset_name)\n",
    "\n",
    "    proc_dir = data['proc_dir']\n",
    "    if not os.path.exists(proc_dir):\n",
    "        os.mkdir(proc_dir)\n",
    "\n",
    "    recon_type = data.get(\"recon_type\", \"full\")\n",
    "\n",
    "    cmd = f\"tomopy recon --file-name {dataset_path} --output-folder {proc_dir} --reconstruction-type {recon_type}\"\n",
    "    result = subprocess.run(cmd.split(\" \"), stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    return result.stdout\n",
    "\n",
    "recon_fxid = fxc.register_function(tomo_recon, container_uuid=tomo_cont_id)"
   ]
  },
  {
   "source": [
    "# Flow Check Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import json\n",
    "from pprint import pprint\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def flow_check(flow_action, refresh=10):\n",
    "    \n",
    "    start = datetime.fromisoformat(flow_action['start_time'])\n",
    "\n",
    "    while True:\n",
    "        flow_action_id = flow_action['action_id']\n",
    "        flow_action = flows_client.flow_action_status(flow_id, flow_scope, flow_action_id)\n",
    "        flow_status = flow_action['status']\n",
    "\n",
    "        print(f'Flow status: {flow_status}')\n",
    "        \n",
    "        if flow_status == 'ACTIVE': \n",
    "            now = datetime.now(timezone.utc)\n",
    "            print(f'Time elapsed: {now - start}')\n",
    "            pprint(json.dumps(flow_action.data, indent = 2, sort_keys=True))\n",
    "\n",
    "        elif flow_status == 'FAILED':\n",
    "            complete = datetime.fromisoformat(flow_action['completion_time'])\n",
    "            print(f'Time elapsed: {complete - start}')\n",
    "            break\n",
    "        elif flow_status == 'SUCCEEDED':\n",
    "            complete = datetime.fromisoformat(flow_action['completion_time'])\n",
    "            print(f'Time elapsed: {complete - start}')\n",
    "            break\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        time.sleep(refresh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flow_definition = {\n",
    "  \"Comment\": \"Tomo Reconstruction\",\n",
    "  \"StartAt\": \"Download Container\",\n",
    "  \"States\": {\n",
    "    \"Download Container\": {\n",
    "      \"Comment\": \"Download the container\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://api.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/all\",\n",
    "      \"Parameters\": {\n",
    "          \"tasks\": [{\n",
    "            \"endpoint.$\": \"$.input.funcx_local_ep\",\n",
    "            \"func.$\": \"$.input.download_cont_fxid\",\n",
    "            \"payload.$\": \"$.input\"\n",
    "        }]\n",
    "      },\n",
    "      \"ResultPath\": \"$.Exec1Result\",\n",
    "      \"WaitTime\": 600,\n",
    "      \"Next\": \"Download Data\"\n",
    "    },\n",
    "    \"Download Data\": {\n",
    "      \"Comment\": \"Download the data\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://api.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/all\",\n",
    "      \"Parameters\": {\n",
    "          \"tasks\": [{\n",
    "            \"endpoint.$\": \"$.input.funcx_local_ep\",\n",
    "            \"func.$\": \"$.input.download_data_fxid\",\n",
    "            \"payload.$\": \"$.input\"\n",
    "        }]\n",
    "      },\n",
    "      \"ResultPath\": \"$.Exec2Result\",\n",
    "      \"WaitTime\": 600,\n",
    "      \"Next\": \"Tomopy Recon\"\n",
    "    },\n",
    "    \"Tomopy Recon\": {\n",
    "      \"Comment\": \"Reconstruct full tomogram\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://api.funcx.org/automate\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/all\",\n",
    "      \"Parameters\": {\n",
    "          \"tasks\": [{\n",
    "            \"endpoint.$\": \"$.input.funcx_ep\",\n",
    "            \"func.$\": \"$.input.recon_fxid\",\n",
    "            \"payload.$\": \"$.input\"\n",
    "        }]\n",
    "      },\n",
    "      \"ResultPath\": \"$.Exec3Result\",\n",
    "      \"WaitTime\": 3600,\n",
    "      \"End\": True\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flow = flows_client.deploy_flow(flow_definition, title=\"Tomo Example flow\")\n",
    "flow_id = flow['id']\n",
    "flow_scope = flow['globus_auth_scope']\n",
    "print(f'Newly created flow with id:\\n{flow_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define input for the flow\n",
    "\n",
    "The input to the flow needs to specify what data to process, where it is located, and where to put it for analysis. The flow also requires the funcX function endpoint ids to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the name for the processing folder intermediate results\n",
    "experiment_name = 'braid_tomo'\n",
    "run_name = experiment_name + '_' + shortuuid.uuid()\n",
    "\n",
    "print(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_input = {\n",
    "    \"input\": {\n",
    "        #HTTPS-Download Container variables\n",
    "        \"container_server_url\":\"https://45a53408-c797-11e6-9c33-22000a1e3b52.e.globus.org/Braid/containers\",\n",
    "        \"container_name\": container_name,\n",
    "        \"container_path\": conf['cont_dir'], ##defined in the funcx container configuration\n",
    "        \"headers\": headers,\n",
    "\n",
    "        #SingleFile-Download variables\n",
    "        \"dataset_server_url\": \"https://45a53408-c797-11e6-9c33-22000a1e3b52.e.globus.org/Braid/data/tomo_example\",\n",
    "        \"dataset_name\": \"tooth.h5\",\n",
    "        \"data_dir\": conf['data_dir'],\n",
    "\n",
    "        #Processing variables\n",
    "        \"proc_dir\": os.path.join(conf['proc_dir'],run_name),\n",
    "\n",
    "        #Tomopy specific variables\n",
    "        \"recon_type\": \"full\",\n",
    "\n",
    "        #Tomopy funcX functions\n",
    "        \"recon_fxid\": recon_fxid,\n",
    "        \n",
    "        #Utility funcX functions\n",
    "        \"download_cont_fxid\": download_cont_fxid,\n",
    "        \"download_data_fxid\": download_data_fxid,\n",
    "\n",
    "        # funcX endpoints\n",
    "        \"funcx_ep\": conf['endpoint'],\n",
    "        \"funcx_local_ep\": conf['local_endpoint'],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the flow\n",
    "\n",
    "This will require you to authenticate and grant access to the flow to use Transfer and funcX on your behalf.\n",
    "\n",
    "The flow should take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flow_action = flows_client.run_flow(flow_id, flow_scope, flow_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_check(flow_action, refresh=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('funcx': conda)",
   "metadata": {
    "interpreter": {
     "hash": "29c7d61c0b705a1e0ee1ff93d2482337e8314a272648cd14c87bbb9c779684f0"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}